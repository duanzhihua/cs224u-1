{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework and bake-off: Word similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Christopher Potts\"\n",
    "__version__ = \"CS224u, Stanford, Spring 2020\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Overview](#Overview)\n",
    "1. [Set-up](#Set-up)\n",
    "1. [Dataset readers](#Dataset-readers)\n",
    "1. [Dataset comparisons](#Dataset-comparisons)\n",
    "  1. [Vocab overlap](#Vocab-overlap)\n",
    "  1. [Pair overlap and score correlations](#Pair-overlap-and-score-correlations)\n",
    "1. [Evaluation](#Evaluation)\n",
    "  1. [Dataset evaluation](#Dataset-evaluation)\n",
    "  1. [Dataset error analysis](#Dataset-error-analysis)\n",
    "  1. [Full evaluation](#Full-evaluation)\n",
    "1. [Homework questions](#Homework-questions)\n",
    "  1. [PPMI as a baseline [0.5 points]](#PPMI-as-a-baseline-[0.5-points])\n",
    "  1. [Gigaword with LSA at different dimensions [0.5 points]](#Gigaword-with-LSA-at-different-dimensions-[0.5-points])\n",
    "  1. [Gigaword with GloVe for a small number of iterations [0.5 points]](#Gigaword-with-GloVe-for-a-small-number-of-iterations-[0.5-points])\n",
    "  1. [Dice coefficient [0.5 points]](#Dice-coefficient-[0.5-points])\n",
    "  1. [t-test reweighting [2 points]](#t-test-reweighting-[2-points])\n",
    "  1. [Enriching a VSM with subword information [2 points]](#Enriching-a-VSM-with-subword-information-[2-points])\n",
    "  1. [Your original system [3 points]](#Your-original-system-[3-points])\n",
    "1. [Bake-off [1 point]](#Bake-off-[1-point])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Word similarity datasets have long been used to evaluate distributed representations. This notebook provides basic code for conducting such analyses with a number of datasets:\n",
    "\n",
    "| Dataset | Pairs | Task-type | Current best Spearman $\\rho$ | Best $\\rho$ paper |   |\n",
    "|---------|-------|-----------|------------------------------|-------------------|---|\n",
    "| [WordSim-353](http://www.cs.technion.ac.il/~gabr/resources/data/wordsim353/) | 353 | Relatedness | 82.8 | [Speer et al. 2017](https://arxiv.org/abs/1612.03975) |\n",
    "| [MTurk-771](http://www2.mta.ac.il/~gideon/mturk771.html) | 771 | Relatedness | 81.0 | [Speer et al. 2017](https://arxiv.org/abs/1612.03975) |\n",
    "| [The MEN Test Collection](http://clic.cimec.unitn.it/~elia.bruni/MEN) | 3,000 | Relatedness | 86.6 | [Speer et al. 2017](https://arxiv.org/abs/1612.03975)  | \n",
    "| [SimVerb-3500-dev](http://people.ds.cam.ac.uk/dsg40/simverb.html) | 500 | Similarity | 61.1 | [Mrki&scaron;&cacute; et al. 2016](https://arxiv.org/pdf/1603.00892.pdf) |\n",
    "| [SimVerb-3500-test](http://people.ds.cam.ac.uk/dsg40/simverb.html) | 3,000 | Similarity | 62.4 | [Mrki&scaron;&cacute; et al. 2016](https://arxiv.org/pdf/1603.00892.pdf) |\n",
    "\n",
    "Each of the similarity datasets contains word pairs with an associated human-annotated similarity score. (We convert these to distances to align intuitively with our distance measure functions.) The evaluation code measures the distance between the word pairs in your chosen VSM (which should be a `pd.DataFrame`).\n",
    "\n",
    "The evaluation metric for each dataset is the [Spearman correlation coefficient $\\rho$](https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient) between the annotated scores and your distances, as is standard in the literature. We also macro-average these correlations across the datasets for an overall summary. (In using the macro-average, we are saying that we care about all the datasets equally, even though they vary in size.)\n",
    "\n",
    "This homework ([questions at the bottom of this notebook](#Homework-questions)) asks you to write code that uses the count matrices in `data/vsmdata` to create and evaluate some baseline models as well as an original model $M$ that you design. This accounts for 9 of the 10 points for this assignment.\n",
    "\n",
    "For the associated bake-off, we will distribute two new word similarity or relatedness datasets and associated reader code, and you will evaluate $M$ (no additional training or tuning allowed!) on those new datasets. Systems that enter will receive the additional homework point, and systems that achieve the top score will receive an additional 0.5 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "import vsm\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VSM_HOME = os.path.join('data', 'vsmdata')\n",
    "\n",
    "WORDSIM_HOME = os.path.join('data', 'wordsim')\n",
    "\n",
    "DATA_HOME = os.path.join('data', 'vsmdata')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset readers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordsim_dataset_reader(\n",
    "        src_filename, \n",
    "        header=False, \n",
    "        delimiter=',', \n",
    "        score_col_index=2):\n",
    "    \"\"\"Basic reader that works for all similarity datasets. They are \n",
    "    all tabular-style releases where the first two columns give the \n",
    "    word and a later column (`score_col_index`) gives the score.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    src_filename : str\n",
    "        Full path to the source file.\n",
    "    header : bool\n",
    "        Whether `src_filename` has a header. Default: False\n",
    "    delimiter : str\n",
    "        Field delimiter in `src_filename`. Default: ','\n",
    "    score_col_index : int\n",
    "        Column containing the similarity scores Default: 2\n",
    "\n",
    "    Yields\n",
    "    ------\n",
    "    (str, str, float)\n",
    "       (w1, w2, score) where `score` is the negative of the similarity\n",
    "       score in the file so that we are intuitively aligned with our\n",
    "       distance-based code. To align with our VSMs, all the words are \n",
    "       downcased.\n",
    "\n",
    "    \"\"\"\n",
    "    with open(src_filename) as f:\n",
    "        reader = csv.reader(f, delimiter=delimiter)\n",
    "        if header:\n",
    "            next(reader)\n",
    "        for row in reader:\n",
    "            w1 = row[0].strip().lower()\n",
    "            w2 = row[1].strip().lower()\n",
    "            score = row[score_col_index]\n",
    "            # Negative of scores to align intuitively with distance functions:\n",
    "            score = -float(score)\n",
    "            yield (w1, w2, score)\n",
    "\n",
    "def wordsim353_reader():\n",
    "    \"\"\"WordSim-353: http://www.cs.technion.ac.il/~gabr/resources/data/wordsim353/\"\"\"\n",
    "    src_filename = os.path.join(\n",
    "        WORDSIM_HOME, 'wordsim353', 'combined.csv')\n",
    "    return wordsim_dataset_reader(\n",
    "        src_filename, header=True)\n",
    "\n",
    "def mturk771_reader():\n",
    "    \"\"\"MTURK-771: http://www2.mta.ac.il/~gideon/mturk771.html\"\"\"\n",
    "    src_filename = os.path.join(\n",
    "        WORDSIM_HOME, 'MTURK-771.csv')\n",
    "    return wordsim_dataset_reader(\n",
    "        src_filename, header=False)\n",
    "\n",
    "def simverb3500dev_reader():\n",
    "    \"\"\"SimVerb-3500: http://people.ds.cam.ac.uk/dsg40/simverb.html\"\"\"\n",
    "    src_filename = os.path.join(\n",
    "        WORDSIM_HOME, 'SimVerb-3500', 'SimVerb-500-dev.txt')\n",
    "    return wordsim_dataset_reader(\n",
    "        src_filename, delimiter=\"\\t\", header=False, score_col_index=3)\n",
    "\n",
    "def simverb3500test_reader():\n",
    "    \"\"\"SimVerb-3500: http://people.ds.cam.ac.uk/dsg40/simverb.html\"\"\"\n",
    "    src_filename = os.path.join(\n",
    "        WORDSIM_HOME, 'SimVerb-3500', 'SimVerb-3000-test.txt')\n",
    "    return wordsim_dataset_reader(\n",
    "        src_filename, delimiter=\"\\t\", header=False, score_col_index=3)\n",
    "\n",
    "def men_reader():\n",
    "    \"\"\"MEN: http://clic.cimec.unitn.it/~elia.bruni/MEN\"\"\"\n",
    "    src_filename = os.path.join(\n",
    "        WORDSIM_HOME, 'MEN', 'MEN_dataset_natural_form_full')\n",
    "    return wordsim_dataset_reader(\n",
    "        src_filename, header=False, delimiter=' ') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This collection of readers will be useful for flexible evaluations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "READERS = (wordsim353_reader, mturk771_reader, simverb3500dev_reader, \n",
    "           simverb3500test_reader, men_reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset comparisons\n",
    "\n",
    "This section does some basic analysis of the datasets. The goal is to obtain a deeper understanding of what problem we're solving – what strengths and weaknesses the datasets have and how they relate to each other. For a full-fledged project, we would want to continue work like this and report on it in the paper, to provide context for the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reader_name(reader):\n",
    "    \"\"\"Return a cleaned-up name for the similarity dataset \n",
    "    iterator `reader`\n",
    "    \"\"\"\n",
    "    return reader.__name__.replace(\"_reader\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocab overlap\n",
    "\n",
    "How many vocabulary items are shared across the datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reader_vocab(reader):\n",
    "    \"\"\"Return the set of words (str) in `reader`.\"\"\"\n",
    "    vocab = set()\n",
    "    for w1, w2, _ in reader():\n",
    "        vocab.add(w1)\n",
    "        vocab.add(w2)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordsim353\twordsim353\n",
      "wordsim353\tmturk771\n",
      "wordsim353\tsimverb3500dev\n",
      "wordsim353\tsimverb3500test\n",
      "wordsim353\tmen\n",
      "mturk771\twordsim353\n",
      "mturk771\tmturk771\n",
      "mturk771\tsimverb3500dev\n",
      "mturk771\tsimverb3500test\n",
      "mturk771\tmen\n",
      "simverb3500dev\twordsim353\n",
      "simverb3500dev\tmturk771\n",
      "simverb3500dev\tsimverb3500dev\n",
      "simverb3500dev\tsimverb3500test\n",
      "simverb3500dev\tmen\n",
      "simverb3500test\twordsim353\n",
      "simverb3500test\tmturk771\n",
      "simverb3500test\tsimverb3500dev\n",
      "simverb3500test\tsimverb3500test\n",
      "simverb3500test\tmen\n",
      "men\twordsim353\n",
      "men\tmturk771\n",
      "men\tsimverb3500dev\n",
      "men\tsimverb3500test\n",
      "men\tmen\n"
     ]
    }
   ],
   "source": [
    "def get_reader_vocab_overlap_test(readers=READERS):\n",
    "    \"\"\"Get data on the vocab-level relationships between pairs of \n",
    "    readers. Returns a a pd.DataFrame containing this information.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for r1, r2 in itertools.product(readers, repeat=2):       \n",
    "        print(get_reader_name(r1) + \"\\t\" + get_reader_name(r2))\n",
    "        \n",
    "get_reader_vocab_overlap_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reader_vocab_overlap(readers=READERS):\n",
    "    \"\"\"Get data on the vocab-level relationships between pairs of \n",
    "    readers. Returns a a pd.DataFrame containing this information.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    # repeat so that the list of (readers),(readers) is crossed with itself\n",
    "    # there will be an instance of reader with itself\n",
    "    for r1, r2 in itertools.product(readers, repeat=2):       \n",
    "        v1 = get_reader_vocab(r1)\n",
    "        v2 = get_reader_vocab(r2)\n",
    "        d = {\n",
    "            'd1': get_reader_name(r1),\n",
    "            'd2': get_reader_name(r2),\n",
    "            'overlap': len(v1 & v2), \n",
    "            'union': len(v1 | v2),\n",
    "            'd1_size': len(v1),\n",
    "            'd2_size': len(v2)}\n",
    "        data.append(d)\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_overlap = get_reader_vocab_overlap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>overlap</th>\n",
       "      <th>union</th>\n",
       "      <th>d1_size</th>\n",
       "      <th>d2_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wordsim353</td>\n",
       "      <td>wordsim353</td>\n",
       "      <td>437</td>\n",
       "      <td>437</td>\n",
       "      <td>437</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wordsim353</td>\n",
       "      <td>mturk771</td>\n",
       "      <td>158</td>\n",
       "      <td>1392</td>\n",
       "      <td>437</td>\n",
       "      <td>1113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wordsim353</td>\n",
       "      <td>simverb3500dev</td>\n",
       "      <td>13</td>\n",
       "      <td>960</td>\n",
       "      <td>437</td>\n",
       "      <td>536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wordsim353</td>\n",
       "      <td>simverb3500test</td>\n",
       "      <td>17</td>\n",
       "      <td>1243</td>\n",
       "      <td>437</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wordsim353</td>\n",
       "      <td>men</td>\n",
       "      <td>86</td>\n",
       "      <td>1102</td>\n",
       "      <td>437</td>\n",
       "      <td>751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mturk771</td>\n",
       "      <td>wordsim353</td>\n",
       "      <td>158</td>\n",
       "      <td>1392</td>\n",
       "      <td>1113</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mturk771</td>\n",
       "      <td>mturk771</td>\n",
       "      <td>1113</td>\n",
       "      <td>1113</td>\n",
       "      <td>1113</td>\n",
       "      <td>1113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mturk771</td>\n",
       "      <td>simverb3500dev</td>\n",
       "      <td>67</td>\n",
       "      <td>1582</td>\n",
       "      <td>1113</td>\n",
       "      <td>536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mturk771</td>\n",
       "      <td>simverb3500test</td>\n",
       "      <td>94</td>\n",
       "      <td>1842</td>\n",
       "      <td>1113</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mturk771</td>\n",
       "      <td>men</td>\n",
       "      <td>230</td>\n",
       "      <td>1634</td>\n",
       "      <td>1113</td>\n",
       "      <td>751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>simverb3500dev</td>\n",
       "      <td>wordsim353</td>\n",
       "      <td>13</td>\n",
       "      <td>960</td>\n",
       "      <td>536</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>simverb3500dev</td>\n",
       "      <td>mturk771</td>\n",
       "      <td>67</td>\n",
       "      <td>1582</td>\n",
       "      <td>536</td>\n",
       "      <td>1113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>simverb3500dev</td>\n",
       "      <td>simverb3500dev</td>\n",
       "      <td>536</td>\n",
       "      <td>536</td>\n",
       "      <td>536</td>\n",
       "      <td>536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>simverb3500dev</td>\n",
       "      <td>simverb3500test</td>\n",
       "      <td>532</td>\n",
       "      <td>827</td>\n",
       "      <td>536</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>simverb3500dev</td>\n",
       "      <td>men</td>\n",
       "      <td>23</td>\n",
       "      <td>1264</td>\n",
       "      <td>536</td>\n",
       "      <td>751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>simverb3500test</td>\n",
       "      <td>wordsim353</td>\n",
       "      <td>17</td>\n",
       "      <td>1243</td>\n",
       "      <td>823</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>simverb3500test</td>\n",
       "      <td>mturk771</td>\n",
       "      <td>94</td>\n",
       "      <td>1842</td>\n",
       "      <td>823</td>\n",
       "      <td>1113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>simverb3500test</td>\n",
       "      <td>simverb3500dev</td>\n",
       "      <td>532</td>\n",
       "      <td>827</td>\n",
       "      <td>823</td>\n",
       "      <td>536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>simverb3500test</td>\n",
       "      <td>simverb3500test</td>\n",
       "      <td>823</td>\n",
       "      <td>823</td>\n",
       "      <td>823</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>simverb3500test</td>\n",
       "      <td>men</td>\n",
       "      <td>30</td>\n",
       "      <td>1544</td>\n",
       "      <td>823</td>\n",
       "      <td>751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>men</td>\n",
       "      <td>wordsim353</td>\n",
       "      <td>86</td>\n",
       "      <td>1102</td>\n",
       "      <td>751</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>men</td>\n",
       "      <td>mturk771</td>\n",
       "      <td>230</td>\n",
       "      <td>1634</td>\n",
       "      <td>751</td>\n",
       "      <td>1113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>men</td>\n",
       "      <td>simverb3500dev</td>\n",
       "      <td>23</td>\n",
       "      <td>1264</td>\n",
       "      <td>751</td>\n",
       "      <td>536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>men</td>\n",
       "      <td>simverb3500test</td>\n",
       "      <td>30</td>\n",
       "      <td>1544</td>\n",
       "      <td>751</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>men</td>\n",
       "      <td>men</td>\n",
       "      <td>751</td>\n",
       "      <td>751</td>\n",
       "      <td>751</td>\n",
       "      <td>751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 d1               d2  overlap  union  d1_size  d2_size\n",
       "0        wordsim353       wordsim353      437    437      437      437\n",
       "1        wordsim353         mturk771      158   1392      437     1113\n",
       "2        wordsim353   simverb3500dev       13    960      437      536\n",
       "3        wordsim353  simverb3500test       17   1243      437      823\n",
       "4        wordsim353              men       86   1102      437      751\n",
       "5          mturk771       wordsim353      158   1392     1113      437\n",
       "6          mturk771         mturk771     1113   1113     1113     1113\n",
       "7          mturk771   simverb3500dev       67   1582     1113      536\n",
       "8          mturk771  simverb3500test       94   1842     1113      823\n",
       "9          mturk771              men      230   1634     1113      751\n",
       "10   simverb3500dev       wordsim353       13    960      536      437\n",
       "11   simverb3500dev         mturk771       67   1582      536     1113\n",
       "12   simverb3500dev   simverb3500dev      536    536      536      536\n",
       "13   simverb3500dev  simverb3500test      532    827      536      823\n",
       "14   simverb3500dev              men       23   1264      536      751\n",
       "15  simverb3500test       wordsim353       17   1243      823      437\n",
       "16  simverb3500test         mturk771       94   1842      823     1113\n",
       "17  simverb3500test   simverb3500dev      532    827      823      536\n",
       "18  simverb3500test  simverb3500test      823    823      823      823\n",
       "19  simverb3500test              men       30   1544      823      751\n",
       "20              men       wordsim353       86   1102      751      437\n",
       "21              men         mturk771      230   1634      751     1113\n",
       "22              men   simverb3500dev       23   1264      751      536\n",
       "23              men  simverb3500test       30   1544      751      823\n",
       "24              men              men      751    751      751      751"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_overlap_crosstab(vocab_overlap):\n",
    "    \"\"\"Return an intuitively formatted `pd.DataFrame` giving \n",
    "    vocab-overlap counts for all the datasets represented in \n",
    "    `vocab_overlap`, the output of `get_reader_vocab_overlap`.\n",
    "    \"\"\"        \n",
    "    xtab = pd.crosstab(\n",
    "        vocab_overlap['d1'], \n",
    "        vocab_overlap['d2'], \n",
    "        values=vocab_overlap['overlap'], \n",
    "        aggfunc=np.mean)\n",
    "    # Blank out the upper right to reduce visual clutter:\n",
    "    for i in range(0, xtab.shape[0]):\n",
    "        for j in range(i+1, xtab.shape[1]):\n",
    "            xtab.iloc[i, j] = ''        \n",
    "    return xtab        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>d2</th>\n",
       "      <th>men</th>\n",
       "      <th>mturk771</th>\n",
       "      <th>simverb3500dev</th>\n",
       "      <th>simverb3500test</th>\n",
       "      <th>wordsim353</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>men</th>\n",
       "      <td>751</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mturk771</th>\n",
       "      <td>230</td>\n",
       "      <td>1113</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simverb3500dev</th>\n",
       "      <td>23</td>\n",
       "      <td>67</td>\n",
       "      <td>536</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simverb3500test</th>\n",
       "      <td>30</td>\n",
       "      <td>94</td>\n",
       "      <td>532</td>\n",
       "      <td>823</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordsim353</th>\n",
       "      <td>86</td>\n",
       "      <td>158</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "d2               men mturk771 simverb3500dev simverb3500test wordsim353\n",
       "d1                                                                     \n",
       "men              751                                                   \n",
       "mturk771         230     1113                                          \n",
       "simverb3500dev    23       67            536                           \n",
       "simverb3500test   30       94            532             823           \n",
       "wordsim353        86      158             13              17        437"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_overlap_crosstab(vocab_overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks reasonable. By design, the SimVerb dev and test sets have a lot of overlap. The other overlap numbers are pretty small, even adjusting for dataset size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pair overlap and score correlations\n",
    "\n",
    "How many word pairs are shared across datasets and, for shared pairs, what is the correlation between their scores? That is, do the datasets agree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reader_pairs(reader):\n",
    "    \"\"\"Return the set of alphabetically-sorted word (str) tuples \n",
    "    in `reader`\n",
    "    \"\"\"\n",
    "    return {tuple(sorted([w1, w2])): score for w1, w2, score in reader()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: review this file\n",
    "def get_reader_pair_overlap(readers=READERS):\n",
    "    \"\"\"Return a `pd.DataFrame` giving the number of overlapping \n",
    "    word-pairs in pairs of readers, along with the Spearman \n",
    "    correlations.\n",
    "    \"\"\"    \n",
    "    data = []\n",
    "    for r1, r2 in itertools.product(READERS, repeat=2):\n",
    "        if r1.__name__ != r2.__name__:\n",
    "            d1 = get_reader_pairs(r1)\n",
    "            d2 = get_reader_pairs(r2)\n",
    "            overlap = []\n",
    "            for p, s in d1.items():   # w1, w2\n",
    "                if p in d2:\n",
    "                    overlap.append([s, d2[p]])\n",
    "            if overlap:\n",
    "                s1, s2 = zip(*overlap)\n",
    "                rho = spearmanr(s1, s2)[0]\n",
    "            else:\n",
    "                rho = None\n",
    "            # Canonical order for the pair:\n",
    "            n1, n2 = sorted([get_reader_name(r1), get_reader_name(r2)])\n",
    "            d = {\n",
    "                'd1': n1,\n",
    "                'd2': n2,\n",
    "                'pair_overlap': len(overlap),\n",
    "                'rho': rho}\n",
    "            data.append(d)\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.sort_values(['pair_overlap','d1','d2'], ascending=False)\n",
    "    # Return only every other row to avoid repeats:\n",
    "    return df[::2].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>pair_overlap</th>\n",
       "      <th>rho</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>men</td>\n",
       "      <td>mturk771</td>\n",
       "      <td>11</td>\n",
       "      <td>0.592191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>men</td>\n",
       "      <td>wordsim353</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mturk771</td>\n",
       "      <td>simverb3500test</td>\n",
       "      <td>4</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>men</td>\n",
       "      <td>simverb3500test</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>simverb3500dev</td>\n",
       "      <td>simverb3500test</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>simverb3500test</td>\n",
       "      <td>wordsim353</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>simverb3500dev</td>\n",
       "      <td>wordsim353</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mturk771</td>\n",
       "      <td>wordsim353</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mturk771</td>\n",
       "      <td>simverb3500dev</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>men</td>\n",
       "      <td>simverb3500dev</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                d1               d2  pair_overlap       rho\n",
       "0              men         mturk771            11  0.592191\n",
       "1              men       wordsim353             5  0.700000\n",
       "2         mturk771  simverb3500test             4  0.400000\n",
       "3              men  simverb3500test             2  1.000000\n",
       "4   simverb3500dev  simverb3500test             1       NaN\n",
       "5  simverb3500test       wordsim353             0       NaN\n",
       "6   simverb3500dev       wordsim353             0       NaN\n",
       "7         mturk771       wordsim353             0       NaN\n",
       "8         mturk771   simverb3500dev             0       NaN\n",
       "9              men   simverb3500dev             0       NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    display(get_reader_pair_overlap())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks reasonable: none of the datasets have a lot of overlapping pairs, so we don't have to worry too much about places where they give conflicting scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "This section builds up the evaluation code that you'll use for the homework and bake-off. For illustrations, I'll read in a VSM created from `data/vsmdata/giga_window5-scaled.csv.gz`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "giga5 = pd.read_csv(\n",
    "    os.path.join(VSM_HOME, \"giga_window5-scaled.csv.gz\"), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>);</th>\n",
       "      <th>.</th>\n",
       "      <th>...</th>\n",
       "      <th>;p</th>\n",
       "      <th>&lt;/p&gt;</th>\n",
       "      <th>&lt;p&gt;</th>\n",
       "      <th>?</th>\n",
       "      <th>___</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>...</th>\n",
       "      <th>younger</th>\n",
       "      <th>youth</th>\n",
       "      <th>yugoslav</th>\n",
       "      <th>yugoslavia</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zebra</th>\n",
       "      <th>zinc</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>505797.700000</td>\n",
       "      <td>70.416667</td>\n",
       "      <td>2.222757e+04</td>\n",
       "      <td>2170.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.968388e+04</td>\n",
       "      <td>3.173778e+04</td>\n",
       "      <td>4002.300000</td>\n",
       "      <td>125.566667</td>\n",
       "      <td>9.616667</td>\n",
       "      <td>...</td>\n",
       "      <td>21.883333</td>\n",
       "      <td>27.333333</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>29.466667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>6.716667</td>\n",
       "      <td>31.216667</td>\n",
       "      <td>7.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>);</th>\n",
       "      <td>70.416667</td>\n",
       "      <td>82566.466667</td>\n",
       "      <td>5.458767e+03</td>\n",
       "      <td>52.783333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.229000e+02</td>\n",
       "      <td>3.551833e+02</td>\n",
       "      <td>107.150000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>7.116667</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>20.516667</td>\n",
       "      <td>29.800000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>11.516667</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>22227.566667</td>\n",
       "      <td>5458.766667</td>\n",
       "      <td>1.292838e+08</td>\n",
       "      <td>57251.566667</td>\n",
       "      <td>1.283333</td>\n",
       "      <td>2.472612e+07</td>\n",
       "      <td>1.628606e+07</td>\n",
       "      <td>91649.616667</td>\n",
       "      <td>77951.066667</td>\n",
       "      <td>6884.516667</td>\n",
       "      <td>...</td>\n",
       "      <td>11487.250000</td>\n",
       "      <td>9965.250000</td>\n",
       "      <td>9101.600000</td>\n",
       "      <td>24068.816667</td>\n",
       "      <td>18217.833333</td>\n",
       "      <td>365.216667</td>\n",
       "      <td>1102.700000</td>\n",
       "      <td>221.783333</td>\n",
       "      <td>19746.083333</td>\n",
       "      <td>3199.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>2170.100000</td>\n",
       "      <td>52.783333</td>\n",
       "      <td>5.725157e+04</td>\n",
       "      <td>923609.433333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.747483e+04</td>\n",
       "      <td>5.099698e+04</td>\n",
       "      <td>5061.033333</td>\n",
       "      <td>294.200000</td>\n",
       "      <td>36.783333</td>\n",
       "      <td>...</td>\n",
       "      <td>40.333333</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>19.633333</td>\n",
       "      <td>66.950000</td>\n",
       "      <td>39.716667</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>79.233333</td>\n",
       "      <td>11.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>;p</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.283333e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>360707.000000</td>\n",
       "      <td>2.883333e+01</td>\n",
       "      <td>2.125000e+01</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 !            );             .            ...             ;p  \\\n",
       "!    505797.700000     70.416667  2.222757e+04    2170.100000       0.000000   \n",
       ");       70.416667  82566.466667  5.458767e+03      52.783333       0.000000   \n",
       ".     22227.566667   5458.766667  1.292838e+08   57251.566667       1.283333   \n",
       "...    2170.100000     52.783333  5.725157e+04  923609.433333       0.000000   \n",
       ";p        0.000000      0.000000  1.283333e+00       0.000000  360707.000000   \n",
       "\n",
       "             </p>           <p>             ?           ___    abandoned  ...  \\\n",
       "!    3.968388e+04  3.173778e+04   4002.300000    125.566667     9.616667  ...   \n",
       ");   5.229000e+02  3.551833e+02    107.150000      0.700000     0.166667  ...   \n",
       ".    2.472612e+07  1.628606e+07  91649.616667  77951.066667  6884.516667  ...   \n",
       "...  5.747483e+04  5.099698e+04   5061.033333    294.200000    36.783333  ...   \n",
       ";p   2.883333e+01  2.125000e+01      0.333333      0.000000     0.000000  ...   \n",
       "\n",
       "          younger        youth     yugoslav    yugoslavia       zealand  \\\n",
       "!       21.883333    27.333333     2.250000     29.466667      5.000000   \n",
       ");       7.100000     7.116667     7.100000     20.516667     29.800000   \n",
       ".    11487.250000  9965.250000  9101.600000  24068.816667  18217.833333   \n",
       "...     40.333333    42.000000    19.633333     66.950000     39.716667   \n",
       ";p       0.000000     0.000000     0.000000      0.000000      0.000000   \n",
       "\n",
       "          zebra         zinc      zombie          zone          zoo  \n",
       "!      0.366667     0.900000    6.716667     31.216667     7.616667  \n",
       ");     0.400000     1.000000    0.500000     11.516667     1.250000  \n",
       ".    365.216667  1102.700000  221.783333  19746.083333  3199.000000  \n",
       "...    8.200000     0.666667    2.333333     79.233333    11.083333  \n",
       ";p     0.000000     0.000000    0.000000      0.000000     0.000000  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "giga5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_similarity_evaluation(reader, df, distfunc=vsm.cosine):\n",
    "    \"\"\"Word-similarity evalution framework.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    reader : iterator\n",
    "        A reader for a word-similarity dataset. Just has to yield\n",
    "        tuples (word1, word2, score).    \n",
    "    df : pd.DataFrame\n",
    "        The VSM being evaluated.        \n",
    "    distfunc : function mapping vector pairs to floats.\n",
    "        The measure of distance between vectors. Can also be \n",
    "        `vsm.euclidean`, `vsm.matching`, `vsm.jaccard`, as well as \n",
    "        any other float-valued function on pairs of vectors.    \n",
    "        \n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If `df.index` is not a subset of the words in `reader`.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float, data\n",
    "        `float` is the Spearman rank correlation coefficient between \n",
    "        the dataset scores and the similarity values obtained from \n",
    "        `df` using  `distfunc`. This evaluation is sensitive only to \n",
    "        rankings, not to absolute values.  `data` is a `pd.DataFrame` \n",
    "        with columns['word1', 'word2', 'score', 'distance'].\n",
    "        \n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for w1, w2, score in reader():\n",
    "        d = {'word1': w1, 'word2': w2, 'score': score}\n",
    "        for w in [w1, w2]:\n",
    "            if w not in df.index:\n",
    "                raise ValueError(\n",
    "                    \"Word '{}' is in the similarity dataset {} but not in the \"\n",
    "                    \"DataFrame, making this evaluation ill-defined. Please \"\n",
    "                    \"switch to a DataFrame with an appropriate vocabulary.\".\n",
    "                    format(w, get_reader_name(reader))) \n",
    "        d['distance'] = distfunc(df.loc[w1], df.loc[w2])\n",
    "        data.append(d)\n",
    "    data = pd.DataFrame(data)\n",
    "    rho, pvalue = spearmanr(data['score'].values, data['distance'].values)\n",
    "    return rho, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho, eval_df = word_similarity_evaluation(men_reader, giga5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40375964105441753"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>score</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sun</td>\n",
       "      <td>sunlight</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>0.956828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>automobile</td>\n",
       "      <td>car</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>0.979143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>river</td>\n",
       "      <td>water</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>0.970105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stairs</td>\n",
       "      <td>staircase</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>0.980475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>morning</td>\n",
       "      <td>sunrise</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>0.963624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word1      word2  score  distance\n",
       "0         sun   sunlight  -50.0  0.956828\n",
       "1  automobile        car  -50.0  0.979143\n",
       "2       river      water  -49.0  0.970105\n",
       "3      stairs  staircase  -49.0  0.980475\n",
       "4     morning    sunrise  -49.0  0.963624"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>score</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>feathers</td>\n",
       "      <td>truck</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.980545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>festival</td>\n",
       "      <td>whiskers</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.974098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>muscle</td>\n",
       "      <td>tulip</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.982235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>bikini</td>\n",
       "      <td>pizza</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.979855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>bakery</td>\n",
       "      <td>zebra</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.976872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word1     word2  score  distance\n",
       "2995  feathers     truck   -1.0  0.980545\n",
       "2996  festival  whiskers   -1.0  0.974098\n",
       "2997    muscle     tulip   -1.0  0.982235\n",
       "2998    bikini     pizza   -1.0  0.979855\n",
       "2999    bakery     zebra   -0.0  0.976872"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(eval_df.head())\n",
    "display(eval_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset error analysis\n",
    "\n",
    "For error analysis, we can look at the words with the largest delta between the gold score and the distance value in our VSM. We do these comparisons based on ranks, just as with our primary metric (Spearman $\\rho$), and we normalize both rankings so that they have a comparable number of levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_similarity_error_analysis(eval_df):    \n",
    "    eval_df['distance_rank'] = _normalized_ranking(eval_df['distance'])\n",
    "    eval_df['score_rank'] = _normalized_ranking(eval_df['score'])\n",
    "    eval_df['error'] =  abs(eval_df['distance_rank'] - eval_df['score_rank'])\n",
    "    return eval_df.sort_values('error')\n",
    "    \n",
    "    \n",
    "def _normalized_ranking(series):\n",
    "    ranks = series.rank(method='dense') # like min but rank always inc. by one bw groups\n",
    "    return ranks / ranks.sum()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>score</th>\n",
       "      <th>distance</th>\n",
       "      <th>distance_rank</th>\n",
       "      <th>score_rank</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>hummingbird</td>\n",
       "      <td>pelican</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>0.975007</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>2.434543e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2315</th>\n",
       "      <td>lily</td>\n",
       "      <td>pigs</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>0.980834</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>4.016842e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>bucket</td>\n",
       "      <td>girls</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.983473</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>4.151568e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>night</td>\n",
       "      <td>sunset</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>0.968690</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>6.520315e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2062</th>\n",
       "      <td>oak</td>\n",
       "      <td>petals</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>0.979721</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>7.162632e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word1    word2  score  distance  distance_rank  score_rank  \\\n",
       "1041  hummingbird  pelican  -32.0  0.975007       0.000243    0.000244   \n",
       "2315         lily     pigs  -13.0  0.980834       0.000488    0.000487   \n",
       "2951       bucket    girls   -4.0  0.983473       0.000602    0.000603   \n",
       "150         night   sunset  -43.0  0.968690       0.000102    0.000103   \n",
       "2062          oak   petals  -17.0  0.979721       0.000435    0.000436   \n",
       "\n",
       "             error  \n",
       "1041  2.434543e-07  \n",
       "2315  4.016842e-07  \n",
       "2951  4.151568e-07  \n",
       "150   6.520315e-07  \n",
       "2062  7.162632e-07  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_similarity_error_analysis(eval_df).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worst predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>score</th>\n",
       "      <th>distance</th>\n",
       "      <th>distance_rank</th>\n",
       "      <th>score_rank</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>branch</td>\n",
       "      <td>twigs</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>0.984622</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>birds</td>\n",
       "      <td>stork</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>0.987704</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>bloom</td>\n",
       "      <td>tulip</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>0.990993</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>bloom</td>\n",
       "      <td>blossom</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>0.991760</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>bloom</td>\n",
       "      <td>rose</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>0.992406</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word1    word2  score  distance  distance_rank  score_rank     error\n",
       "67   branch    twigs  -45.0  0.984622       0.000630    0.000077  0.000553\n",
       "190   birds    stork  -43.0  0.987704       0.000657    0.000103  0.000554\n",
       "185   bloom    tulip  -43.0  0.990993       0.000663    0.000103  0.000561\n",
       "167   bloom  blossom  -43.0  0.991760       0.000664    0.000103  0.000561\n",
       "198   bloom     rose  -43.0  0.992406       0.000664    0.000103  0.000561"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_similarity_error_analysis(eval_df).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A full evaluation is just a loop over all the readers on which one want to evaluate, with a macro-average at the end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_word_similarity_evaluation(df, readers=READERS, distfunc=vsm.cosine):\n",
    "    \"\"\"Evaluate a VSM against all datasets in `readers`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "    readers : tuple \n",
    "        The similarity dataset readers on which to evaluate.\n",
    "    distfunc : function mapping vector pairs to floats.\n",
    "        The measure of distance between vectors. Can also be \n",
    "        `vsm.euclidean`, `vsm.matching`, `vsm.jaccard`, as well as \n",
    "        any other float-valued function on pairs of vectors.    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        Mapping dataset names to Spearman r values.\n",
    "        \n",
    "    \"\"\"        \n",
    "    scores = {}     \n",
    "    for reader in readers:\n",
    "        score, data_df = word_similarity_evaluation(reader, df, distfunc=distfunc)\n",
    "        scores[get_reader_name(reader)] = score\n",
    "    series = pd.Series(scores, name='Spearman r')\n",
    "    series['Macro-average'] = series.mean()\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wordsim353         0.327831\n",
       "mturk771           0.143146\n",
       "simverb3500dev    -0.065020\n",
       "simverb3500test   -0.066314\n",
       "men                0.403760\n",
       "Macro-average      0.148681\n",
       "Name: Spearman r, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    display(full_word_similarity_evaluation(giga5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework questions\n",
    "\n",
    "Please embed your homework responses in this notebook, and do not delete any cells from the notebook. (You are free to add as many cells as you like as part of your responses.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPMI as a baseline [0.5 points]\n",
    "\n",
    "The insight behind PPMI is a recurring theme in word representation learning, so it is a natural baseline for our task. For this question, write a function called `run_giga_ppmi_baseline` that does the following:\n",
    "\n",
    "1. Reads the Gigaword count matrix with a window of 20 and a flat scaling function into a `pd.DataFrame`s, as is done in the VSM notebooks. The file is `data/vsmdata/giga_window20-flat.csv.gz`, and the VSM notebooks provide examples of the needed code.\n",
    "\n",
    "1. Reweights this count matrix with PPMI.\n",
    "\n",
    "1. Evaluates this reweighted matrix using `full_word_similarity_evaluation`. The return value of `run_giga_ppmi_baseline` should be the return value of this call to `full_word_similarity_evaluation`.\n",
    "\n",
    "The goal of this question is to help you get more familiar with the code in `vsm` and the function `full_word_similarity_evaluation`.\n",
    "\n",
    "The function `test_run_giga_ppmi_baseline` can be used to test that you've implemented this specification correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_giga_ppmi_baseline():\n",
    "   ##### YOUR CODE HERE\n",
    "\tgiga20 = pd.read_csv(\n",
    "\t\tos.path.join(DATA_HOME, 'giga_window20-flat.csv.gz'), index_col=0)\n",
    "\tgiga_20_ppmi = vsm.pmi(giga20)\n",
    "\treturn full_word_similarity_evaluation(giga_20_ppmi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_run_giga_ppmi_baseline(run_giga_ppmi_baseline):\n",
    "    result = run_giga_ppmi_baseline()\n",
    "    ws_result = result.loc['wordsim353'].round(2)\n",
    "    ws_expected = 0.58\n",
    "    assert ws_result == ws_expected, \\\n",
    "        \"Expected wordsim353 value of {}; got {}\".format(ws_expected, ws_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    test_run_giga_ppmi_baseline(run_giga_ppmi_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gigaword with LSA at different dimensions [0.5 points]\n",
    "\n",
    "We might expect PPMI and LSA to form a solid pipeline that combines the strengths of PPMI with those of dimensionality reduction. However, LSA has a hyper-parameter $k$ – the dimensionality of the final representations – that will impact performance. For this problem, write a wrapper function `run_ppmi_lsa_pipeline` that does the following:\n",
    "\n",
    "1. Takes as input a count `pd.DataFrame` and an LSA parameter `k`.\n",
    "1. Reweights the count matrix with PPMI.\n",
    "1. Applies LSA with dimensionality `k`.\n",
    "1. Evaluates this reweighted matrix using `full_word_similarity_evaluation`. The return value of `run_ppmi_lsa_pipeline` should be the return value of this call to `full_word_similarity_evaluation`.\n",
    "\n",
    "The goal of this question is to help you get a feel for how much LSA alone can contribute to this problem. \n",
    "\n",
    "The  function `test_run_ppmi_lsa_pipeline` will test your function on the count matrix in `data/vsmdata/giga_window20-flat.csv.gz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ppmi_lsa_pipeline(count_df, k):\n",
    "    ##### YOUR CODE HERE\n",
    "\tcount_df_ppmi = vsm.pmi(count_df)  # reweight with ppmi\n",
    "\tcount_df_lsa = vsm.lsa(count_df_ppmi, k=k)\n",
    "\treturn full_word_similarity_evaluation(count_df_lsa)\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_run_ppmi_lsa_pipeline(run_ppmi_lsa_pipeline):\n",
    "    giga20 = pd.read_csv(\n",
    "        os.path.join(VSM_HOME, \"giga_window20-flat.csv.gz\"), index_col=0)\n",
    "    results = run_ppmi_lsa_pipeline(giga20, k=10)\n",
    "    men_expected = 0.57\n",
    "    men_result = results.loc['men'].round(2)\n",
    "    assert men_result == men_expected,\\\n",
    "        \"Expected men value of {}; got {}\".format(men_expected, men_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-47ef09f97ddc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'IS_GRADESCOPE_ENV'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtest_run_ppmi_lsa_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_ppmi_lsa_pipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-bd19a93aaf46>\u001b[0m in \u001b[0;36mtest_run_ppmi_lsa_pipeline\u001b[0;34m(run_ppmi_lsa_pipeline)\u001b[0m\n\u001b[1;32m      2\u001b[0m     giga20 = pd.read_csv(\n\u001b[1;32m      3\u001b[0m         os.path.join(VSM_HOME, \"giga_window20-flat.csv.gz\"), index_col=0)\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_ppmi_lsa_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgiga20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmen_expected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.57\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmen_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'men'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-fba3d9713e5a>\u001b[0m in \u001b[0;36mrun_ppmi_lsa_pipeline\u001b[0;34m(count_df, k)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m##### YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mcount_df_ppmi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvsm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpmi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_df\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# reweight with ppmi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mcount_df_lsa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvsm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlsa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_df_ppmi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfull_word_similarity_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_df_lsa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Prog (git, no gdrive)/cs224u/code/vsm.py\u001b[0m in \u001b[0;36mlsa\u001b[0;34m(df, k)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \"\"\"\n\u001b[0;32m--> 258\u001b[0;31m     \u001b[0mrowmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m     \u001b[0msingvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0mtrunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrowmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msvd\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/nlu/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[1;32m   1624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1625\u001b[0m         \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->DdD'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->ddd'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1626\u001b[0;31m         \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1627\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_realType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    test_run_ppmi_lsa_pipeline(run_ppmi_lsa_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gigaword with GloVe for a small number of iterations [0.5 points]\n",
    "\n",
    "Ideally, we would run GloVe for a very large number of iterations on a GPU machine to compare it against its close cousin PMI. However, we don't want this homework to cost you a lot of money or monopolize a lot of your available computing resources, so let's instead just probe GloVe a little bit to see if it has promise for our task. For this problem, write a function `run_small_glove_evals` that does the following:\n",
    "\n",
    "1. Reads in `data/vsmdata/giga_window20-flat.csv.gz`.\n",
    "1. Runs GloVe for 10, 100, and 200 iterations on `data/vsmdata/giga_window20-flat.csv.gz`, using the `mittens` implementation of `GloVe`. \n",
    "  * For all the other parameters to `mittens.GloVe` besides `max_iter`, use the package's defaults.\n",
    "  * Because of the way that implementation is designed, these will have to be separate runs, but they should be relatively quick. \n",
    "1. Stores the values in a `dict` mapping each `max_iter` value to its associated 'Macro-average' score according to `full_word_similarity_evaluation`. `run_small_glove_evals`  should return this `dict`.\n",
    "\n",
    "The trend should give you a sense for whether it is worth running GloVe for more iterations.\n",
    "\n",
    "Some implementation notes:\n",
    "\n",
    "* Your trained GloVe matrix `X` needs to be wrapped in a `pd.DataFrame` to work with `full_word_similarity_evaluation`. `pd.DataFrame(X, index=giga20.index)` will do the trick.\n",
    "\n",
    "* If `glv` is your GloVe model, then running `glv.sess.close()` after each model is trained will silence warnings from TensorFlow about interactive sessions being active.\n",
    "\n",
    "Performance will vary a lot for this function, so there is some uncertainty in the testing, but `test_run_small_glove_evals` will at least check that you wrote a function with the right general logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_small_glove_evals():\n",
    "\tfrom mittens.tf_mittens import Mittens, GloVe\n",
    "\t##### YOUR CODE HERE\n",
    "\tgiga20 = pd.read_csv(\n",
    "\t\tos.path.join(DATA_HOME, 'giga_window20-flat.csv.gz'), index_col=0)\n",
    "\n",
    "\toutput = {}\n",
    "\tfor max_iter in (10, 100, 200):\n",
    "\t\tglv = GloVe(max_iter=max_iter)\n",
    "\t\tembeddings = glv.fit(giga20.values)\n",
    "\t\tglv.sess.close()\n",
    "\t\t\n",
    "\t\tembeddings_df = pd.DataFrame(embeddings, index=giga20.index)\n",
    "\t\teval_df = full_word_similarity_evaluation(embeddings_df)\n",
    "\t\toutput[max_iter] = eval_df['Macro-average']\n",
    "\t\n",
    "\treturn output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_run_small_glove_evals(run_small_glove_evals):\n",
    "    data = run_small_glove_evals()\n",
    "    for max_iter in (10, 100, 200):\n",
    "        assert max_iter in data\n",
    "        assert isinstance(data[max_iter], float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    test_run_small_glove_evals(run_small_glove_evals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dice coefficient [0.5 points]\n",
    "\n",
    "Implement the Dice coefficient for real-valued vectors, as\n",
    "\n",
    "$$\n",
    "\\textbf{dice}(u, v) = \n",
    "1 - \\frac{\n",
    "  2 \\sum_{i=1}^{n}\\min(u_{i}, v_{i})\n",
    "}{\n",
    "    \\sum_{i=1}^{n} u_{i} + v_{i}\n",
    "}$$\n",
    " \n",
    "You can use `test_dice_implementation` below to check that your implementation is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dice_implementation(func):\n",
    "    \"\"\"`func` should be an implementation of `dice` as defined above.\"\"\"\n",
    "    X = np.array([\n",
    "        [  4.,   4.,   2.,   0.],\n",
    "        [  4.,  61.,   8.,  18.],\n",
    "        [  2.,   8.,  10.,   0.],\n",
    "        [  0.,  18.,   0.,   5.]]) \n",
    "    assert func(X[0], X[1]).round(5) == 0.80198\n",
    "    assert func(X[1], X[2]).round(5) == 0.67568"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(u, v):\n",
    "\t##### YOUR CODE HERE\n",
    "\treturn 1 - 2 * np.sum(np.minimum(u, v))/np.sum(u + v)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    test_dice_implementation(dice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-test reweighting [2 points]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The t-test statistic can be thought of as a reweighting scheme. For a count matrix $X$, row index $i$, and column index $j$:\n",
    "\n",
    "$$\\textbf{ttest}(X, i, j) = \n",
    "\\frac{\n",
    "    P(X, i, j) - \\big(P(X, i, *)P(X, *, j)\\big)\n",
    "}{\n",
    "\\sqrt{(P(X, i, *)P(X, *, j))}\n",
    "}$$\n",
    "\n",
    "where $P(X, i, j)$ is $X_{ij}$ divided by the total values in $X$, $P(X, i, *)$ is the sum of the values in row $i$ of $X$ divided by the total values in $X$, and $P(X, *, j)$ is the sum of the values in column $j$ of $X$ divided by the total values in $X$.\n",
    "\n",
    "For this problem, implement this reweighting scheme. You can use `test_ttest_implementation` below to check that your implementation is correct. You do not need to use this for any evaluations, though we hope you will be curious enough to do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ttest_implementation(func):\n",
    "    \"\"\"`func` should be an implementation of t-test reweighting as \n",
    "    defined above.\n",
    "    \"\"\"\n",
    "    X = pd.DataFrame(np.array([\n",
    "        [  4.,   4.,   2.,   0.],\n",
    "        [  4.,  61.,   8.,  18.],\n",
    "        [  2.,   8.,  10.,   0.],\n",
    "        [  0.,  18.,   0.,   5.]]))    \n",
    "    actual = np.array([\n",
    "        [ 0.33056, -0.07689,  0.04321, -0.10532],\n",
    "        [-0.07689,  0.03839, -0.10874,  0.07574],\n",
    "        [ 0.04321, -0.10874,  0.36111, -0.14894],\n",
    "        [-0.10532,  0.07574, -0.14894,  0.05767]])    \n",
    "    predicted = func(X)\n",
    "    assert np.array_equal(predicted.round(5), actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttest(df):\n",
    "    \n",
    "    ##### YOUR CODE HERE\n",
    "\tm = df.values\n",
    "\tX_sum = m.sum()\n",
    "\tX_i = m.sum(axis=1) / X_sum\n",
    "\tX_j = m.sum(axis=0) / X_sum\n",
    "\tX_ij = m / X_sum\n",
    "\t\n",
    "\trows, cols = m.shape\n",
    "\toutput = np.zeros((rows, cols))\n",
    "\tfor i in range(rows):\n",
    "\t\tfor j in range(cols):\n",
    "\t\t\tmult = X_i[i] * X_j[j]\n",
    "\t\t\toutput[i,j] = (X_ij[i,j] - mult) / np.sqrt(mult)\n",
    "\t\n",
    "\treturn output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    test_ttest_implementation(ttest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enriching a VSM with subword information [2 points]\n",
    "\n",
    "It might be useful to combine character-level information with word-level information. To help you begin asssessing this idea, this question asks you to write a function that modifies an existing VSM so that the representation for each word $w$ is the element-wise sum of $w$'s original word-level representation with all the representations for the n-grams $w$ contains. \n",
    "\n",
    "The following starter code should help you structure this and clarify the requirements, and a simple test is included below as well.\n",
    "\n",
    "You don't need to write a lot of code; the motivation for this question is that the function you write could have practical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subword_enrichment(df, n=4):\n",
    "    \n",
    "    # 1. Use `vsm.ngram_vsm` to create a character-level \n",
    "    # VSM from `df`, using the above parameter `n` to \n",
    "    # set the size of the ngrams.\n",
    "    \n",
    "    ##### YOUR CODE HERE\n",
    "\tdf_ngram_vsm = vsm.ngram_vsm(df, n=n)\n",
    "\t\n",
    "    # 2. Use `vsm.character_level_rep` to get the representation\n",
    "    # for every word in `df` according to the character-level\n",
    "    # VSM you created above.\n",
    "    \n",
    "    # 3. For each representation created at step 2, add in its\n",
    "    # original representation from `df`. (This should use\n",
    "    # element-wise addition; the dimensionality of the vectors\n",
    "    # will be unchanged.)\n",
    "                            \n",
    "    ##### YOUR CODE HERE\n",
    "\tnew_reprs = []    # accumulate the new vector reprs, in order\n",
    "\tfor orig_word, x in df.iterrows():\n",
    "\t\tchar_repr_array = vsm.character_level_rep(orig_word, df_ngram_vsm, n=n)\n",
    "\t\tsummed_array = char_repr_array + np.array(x)\n",
    "\t\tnew_reprs.append(summed_array)\n",
    "\t\n",
    "    # 4. Return a `pd.DataFrame` with the same index and column\n",
    "    # values as `df`, but filled with the new representations\n",
    "    # created at step 3.\n",
    "                            \n",
    "    ##### YOUR CODE HERE\n",
    "\treturn pd.DataFrame(new_reprs, index=df.index)  # rows are of the same form as orig df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ABCD</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BCDA</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDAB</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DABC</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3\n",
       "ABCD  1  1  2  1\n",
       "BCDA  3  4  2  4\n",
       "CDAB  0  0  1  0\n",
       "DABC  1  0  0  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;w&gt;AB</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABC</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BCD</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD&lt;/w&gt;</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;w&gt;BC</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDA</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DA&lt;/w&gt;</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;w&gt;CD</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAB</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AB&lt;/w&gt;</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;w&gt;DA</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BC&lt;/w&gt;</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0  1  2  3\n",
       "<w>AB   1  1  2  1\n",
       "ABC     2  1  2  1\n",
       "BCD     4  5  4  5\n",
       "CD</w>  1  1  2  1\n",
       "<w>BC   3  4  2  4\n",
       "CDA     3  4  3  4\n",
       "DA</w>  3  4  2  4\n",
       "<w>CD   0  0  1  0\n",
       "DAB     1  0  1  0\n",
       "AB</w>  0  0  1  0\n",
       "<w>DA   1  0  0  0\n",
       "BC</w>  1  0  0  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[array([1, 1, 2, 1]),\n",
       " array([3, 4, 2, 4]),\n",
       " array([0, 0, 1, 0]),\n",
       " array([1, 0, 0, 0])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ABCD</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BCDA</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDAB</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DABC</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3\n",
       "ABCD  1  1  2  1\n",
       "BCDA  3  4  2  4\n",
       "CDAB  0  0  1  0\n",
       "DABC  1  0  0  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    # 1. Use `vsm.ngram_vsm` to create a character-level \\n    # VSM from `df`, using the above parameter `n` to \\n    # set the size of the ngrams.\\n    \\n    ##### YOUR CODE HERE\\n\\tdf_chars = vsm.ngram_vsm(df, n=n)\\n        \\n    # 2. Use `vsm.character_level_rep` to get the representation\\n    # for every word in `df` according to the character-level\\n    # VSM you created above.\\n    \\n    ##### YOUR CODE HERE\\n\\tword_reps = vsm.characer_level_rep\\n\\n\\n    \\n    # 3. For each representation created at step 2, add in its\\n    # original representation from `df`. (This should use\\n    # element-wise addition; the dimensionality of the vectors\\n    # will be unchanged.)\\n                            \\n    ##### YOUR CODE HERE\\n\\n\\n    \\n    # 4. Return a `pd.DataFrame` with the same index and column\\n    # values as `df`, but filled with the new representations\\n    # created at step 3.\\n                            \\n    ##### YOUR CODE HERE\\n\\n'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = [\"ABCD\", \"BCDA\", \"CDAB\", \"DABC\"]\n",
    "df = pd.DataFrame([\n",
    "\t[1, 1, 2, 1],\n",
    "\t[3, 4, 2, 4],\n",
    "\t[0, 0, 1, 0],\n",
    "\t[1, 0, 0, 0]], index=vocab)\n",
    "\n",
    "display(df)\n",
    "\n",
    "df_ngram_vsm = vsm.ngram_vsm(df, n=3)\n",
    "\n",
    "display(df_ngram_vsm)\n",
    "\n",
    "new_reprs = []\n",
    "for orig_word, x in df.iterrows():\n",
    "\tchar_repr_array = vsm.character_level_rep(orig_word, df_ngram_vsm)\n",
    "\tsummed_array = char_repr_array + np.array(x)\n",
    "\tnew_reprs.append(summed_array)\n",
    "\n",
    "display(new_reprs)\n",
    "\n",
    "display(pd.DataFrame(new_reprs, index=df.index))\n",
    "\n",
    "\"\"\"\n",
    "    # 1. Use `vsm.ngram_vsm` to create a character-level \n",
    "    # VSM from `df`, using the above parameter `n` to \n",
    "    # set the size of the ngrams.\n",
    "    \n",
    "    ##### YOUR CODE HERE\n",
    "\tdf_chars = vsm.ngram_vsm(df, n=n)\n",
    "        \n",
    "    # 2. Use `vsm.character_level_rep` to get the representation\n",
    "    # for every word in `df` according to the character-level\n",
    "    # VSM you created above.\n",
    "    \n",
    "\tword_reps = vsm.characer_level_rep\n",
    "\n",
    "\n",
    "    \n",
    "    # 3. For each representation created at step 2, add in its\n",
    "    # original representation from `df`. (This should use\n",
    "    # element-wise addition; the dimensionality of the vectors\n",
    "    # will be unchanged.)\n",
    "                            \n",
    "    ##### YOUR CODE HERE\n",
    "\n",
    "\n",
    "    \n",
    "    # 4. Return a `pd.DataFrame` with the same index and column\n",
    "    # values as `df`, but filled with the new representations\n",
    "    # created at step 3.\n",
    "                            \n",
    "    ##### YOUR CODE HERE\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_subword_enrichment(func):\n",
    "    \"\"\"`func` should be an implementation of subword_enrichment as \n",
    "    defined above.\n",
    "    \"\"\"\n",
    "    vocab = [\"ABCD\", \"BCDA\", \"CDAB\", \"DABC\"]\n",
    "    df = pd.DataFrame([\n",
    "        [1, 1, 2, 1],\n",
    "        [3, 4, 2, 4],\n",
    "        [0, 0, 1, 0],\n",
    "        [1, 0, 0, 0]], index=vocab)\n",
    "    expected = pd.DataFrame([\n",
    "        [14, 14, 18, 14],\n",
    "        [22, 26, 18, 26],\n",
    "        [10, 10, 14, 10],\n",
    "        [14, 10, 10, 10]], index=vocab)\n",
    "    new_df = func(df, n=2)\n",
    "    assert np.array_equal(expected.columns, new_df.columns), \\\n",
    "        \"Columns are not the same\"\n",
    "    assert np.array_equal(expected.index, new_df.index), \\\n",
    "        \"Indices are not the same\"\n",
    "    assert np.array_equal(expected.values, new_df.values), \\\n",
    "        \"Co-occurrence values aren't the same\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    test_subword_enrichment(subword_enrichment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your original system [3 points]\n",
    "\n",
    "This question asks you to design your own model. You can of course include steps made above (ideally, the above questions informed your system design!), but your model should not be literally identical to any of the above models. Other ideas: retrofitting, autoencoders, GloVe, subword modeling, ... \n",
    "\n",
    "Requirements:\n",
    "\n",
    "1. Your code must operate on one of the count matrices in `data/vsmdata`. You can choose which one. __Other pretrained vectors cannot be introduced__.\n",
    "\n",
    "1. Your code must be self-contained, so that we can work with your model directly in your homework submission notebook. If your model depends on external data or other resources, please submit a ZIP archive containing these resources along with your submission.\n",
    "\n",
    "In the cell below, please provide a brief technical description of your original system, so that the teaching team can gain an understanding of what it does. This will help us to understand your code and analyze all the submissions to identify patterns and strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wordsim353         0.542720\n",
       "mturk771           0.563311\n",
       "simverb3500dev     0.191671\n",
       "simverb3500test    0.161119\n",
       "men                0.687933\n",
       "Macro-average      0.429351\n",
       "Name: Spearman r, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def custom_model(input_data_file):\n",
    "\tdf = pd.read_csv(\n",
    "\t\tos.path.join(DATA_HOME, input_data_file), index_col=0)\n",
    "\t\n",
    "\tdf_subwords = subword_enrichment(df, n=6)\n",
    "\tdf_subword_pmi = vsm.pmi(df_subwords)\n",
    "\tdf_ttest = pd.DataFrame(ttest(df_subword_pmi), index=df.index)\n",
    "\t\n",
    "\t#df_ppmi = vsm.pmi(df)\n",
    "\t#df_ttest = pd.DataFrame(ttest(df_ppmi), index=df.index)\n",
    "\t#final_df = df_subwords_pmi * 0.5 + df_ttest * 0.5\n",
    "\tfinal_df = df_ttest\n",
    "\t\n",
    "\treturn final_df\n",
    "\t\n",
    "\n",
    "giga_window5_scaled = \"giga_window5-scaled.csv.gz\"\n",
    "giga_window20_flat = \"giga_window20-flat.csv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wordsim353         0.604212\n",
       "mturk771           0.587155\n",
       "simverb3500dev     0.318042\n",
       "simverb3500test    0.250915\n",
       "men                0.696400\n",
       "Macro-average      0.491345\n",
       "Name: Spearman r, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for some reason this model performs better than subwords + pmi + ttest\n",
    "def custom_model2(input_data_file):\n",
    "\tdf = pd.read_csv(\n",
    "\t\tos.path.join(DATA_HOME, input_data_file), index_col=0)\n",
    "\t\n",
    "\tdf_pmi = vsm.pmi(df)\n",
    "\t\n",
    "\tfinal_df = df_pmi\n",
    "\t\n",
    "\treturn final_df\n",
    "\t\n",
    "\n",
    "giga_window5_scaled = \"giga_window5-scaled.csv.gz\"\n",
    "giga_window20_flat = \"giga_window20-flat.csv.gz\"\n",
    "\n",
    "custom = custom_model2(giga_window5_scaled)\n",
    "display(full_word_similarity_evaluation(custom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nAfter doing a subword enrichment with n=6, which performed better than n=4,\\nwe do positive PMI reweighting, followed by ttest reweighting.\\n\\nI attempted to take vector combinations in a highway-layer-like fashion, but \\ngot NaNs and didn't have time to work further. I wanted to combine an LSA with\\nthe original vector weights in roughly 1/2 1/2 weightings. \\n\\nI also wanted to try a subword ppmi added to a non-subword ppmi.\\n\\nTtest slowed the model down substantially in training which reduced opportunities\\nto do grid search and to experiment with different model orderings. \\n\\nThe model performs poorly on simverb, which is worth investigating. It might be worth\\ndoing a retrofit, maybe specifically on verb type words (select only verbs from the dataset)\\nand do a retrofit to bring verb representations closer to what simverb expects.\\n\\n\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enter your system description in this cell.\n",
    "# Please do not remove this comment.\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    pass\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "After doing a subword enrichment with n=6, which performed better than n=4,\n",
    "we do positive PMI reweighting, followed by ttest reweighting.\n",
    "\n",
    "I attempted to take vector combinations in a highway-layer-like fashion, but \n",
    "got NaNs and didn't have time to work further. I wanted to combine an LSA with\n",
    "the original vector weights in roughly 1/2 1/2 weightings. \n",
    "\n",
    "I also wanted to try a subword ppmi added to a non-subword ppmi.\n",
    "\n",
    "Ttest slowed the model down substantially in training which reduced opportunities\n",
    "to do grid search and to experiment with different model orderings. \n",
    "\n",
    "The model performs poorly on simverb, which is worth investigating. It might be worth\n",
    "doing a retrofit, maybe specifically on verb type words (select only verbs from the dataset)\n",
    "and do a retrofit to bring verb representations closer to what simverb expects.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bake-off [1 point]\n",
    "\n",
    "For the bake-off, we will release two additional datasets. The announcement will go out on the discussion forum. We will also release reader code for these datasets that you can paste into this notebook. You will evaluate your custom model $M$ (from the previous question) on these new datasets using `full_word_similarity_evaluation`. Rules:\n",
    "\n",
    "1. Only one evaluation is permitted.\n",
    "1. No additional system tuning is permitted once the bake-off has started.\n",
    "\n",
    "The cells below this one constitute your bake-off entry.\n",
    "\n",
    "People who enter will receive the additional homework point, and people whose systems achieve the top score will receive an additional 0.5 points. We will test the top-performing systems ourselves, and only systems for which we can reproduce the reported results will win the extra 0.5 points.\n",
    "\n",
    "Late entries will be accepted, but they cannot earn the extra 0.5 points. Similarly, you cannot win the bake-off unless your homework is submitted on time.\n",
    "\n",
    "The announcement will include the details on where to submit your entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your bake-off assessment code into this cell. \n",
    "# Please do not remove this comment.\n",
    "\n",
    "def mturk287_reader():\n",
    "    \"\"\"MTurk-287: http://tx.technion.ac.il/~kirar/Datasets.html\"\"\"\n",
    "    src_filename = os.path.join(\n",
    "        WORDSIM_HOME, 'bakeoff-wordsim-test-data', 'MTurk-287.csv')\n",
    "    return wordsim_dataset_reader(\n",
    "        src_filename, header=False)\n",
    "\n",
    "def simlex999_reader(wordsim_test_home=WORDSIM_HOME):\n",
    "    \"\"\"SimLex999: https://www.cl.cam.ac.uk/~fh295/SimLex-999.zip\"\"\"\n",
    "    src_filename = os.path.join(\n",
    "        WORDSIM_HOME, 'bakeoff-wordsim-test-data', 'SimLex-999', 'SimLex-999.txt')\n",
    "    return wordsim_dataset_reader(\n",
    "        src_filename, delimiter=\"\\t\", header=True, score_col_index=3)\n",
    "\n",
    "BAKEOFF = (simlex999_reader, mturk287_reader)\n",
    "\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    full_word_similarity_evaluation(custom, readers=BAKEOFF)\n",
    "    pass\n",
    "    # Please enter your code in the scope of the above conditional.\n",
    "    ##### YOUR CODE HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On an otherwise blank line in this cell, please enter\n",
    "# your \"Macro-average\" value as reported by the code above. \n",
    "# Please enter only a number between 0 and 1 inclusive.\n",
    "# Please do not remove this comment.\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    0.481\n",
    "    pass\n",
    "    # Please enter your score in the scope of the above conditional.\n",
    "    ##### YOUR CODE HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
